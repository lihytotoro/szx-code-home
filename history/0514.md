# 0514 进展
目前，已经将多卡推理的代码整合到了 vqa_eval 的目录下
今天尝试跑多组实验：
	1. direct-apr
		1.1 qlora
			可以跑 6 组，base 和 Instruct 模型各运行 3 组，分别对应 load_in_4bit, load_in_8bit, 以及 dtype=torch.float16 的实验设置？
		1.2 lora
			与上面相同，也可以针对两种 codellama-7b 模型和 3 种 load 设置，跑 6 组实验
		注意：现在已经大概印证了：load_in_4bit 可以在 beam=10 的情况下，以低于 40G 的显存占用，进行多卡推理。我们可以再尝试一下 8bit 能否运行，以及换到 g200x 的 A100 上时能否运行！
		后续可以研究一下 4bit、8bit 以及 16bit 的实验设置对于推理效果是否有很大的影响！

    实验情况
    qlora 目前 5 个实验跑完了（多一个 base 模型的 8bit）
    lora：
        model   4bit    gpu     num_gpu time
        base    T       g3027   2       ~30min
        base    F       g3025   8       ~10min
        inst    T       g3025   8
        inst    F       g3025   8

    2. cwe-inference 实验
        注意，本实验的输入输出格式和上面的任务不一致，上面的任务是 buggy -> fixed，而本任务为 buggy -> cwe
        因此，应该修改一下 generate 那里的格式？
        有三个地方需要修改：
            apr_dataset、model（应该增加 qwen 模型的类）、evaluate_VQA
        在此之前，我们先把该跑的 direct-apr 实验都跑完！

        注意，接收的数据文件应该有两种，一种是 java-juliet 的测试集（0.05 或 0.1），另一种是 d4j
        2.1 qlora
            model 统一都是 qwen1.5-7b-chat
            dataset 4bit    gpu     num_gpu     status      time
            d4j     T       g3029   4           re-pro      7:09
            d4j     F       g3029   4           re-pro      5:24
            java-j  T       g3029   4           processing  ~1h40min?
            java-j  F       g3029   4           processing  ~1h10min?
        2.2 lora
            dataset 4bit    gpu     num_gpu     status      time
            d4j     T       g2006   4           re-pro      7:27
            d4j     F       g2006   4           re-pro      3:52
            java-j  T       g2003   4           processing  ~1h20min?
            java-j  F       g2003   4           processing  ~45min?
        2.3 full
            dataset 4bit    gpu     num_gpu     status      time
            d4j     T       g2004   4           processing  6:00
            d4j     F       g2004   4           processing  3:11
            java-j  T       g3027   4           processing  ~1h35min?
            java-j  F       g3027   4           processing  ~50min?

            直接使用原始的模型做推理





# 0519 任务
目前为止跑出来了 cwe-apr 的结果，一次推理 5000 条（beam=1）大概需要 45~90 分钟左右
问题：为什么 4bit 比 non-4bit 推理还要慢不少呢？

目前的任务：再编译出来一套完整的 defects4j 测试套件，并且把每组套件里面的 buggy_clean 的部分解决掉（之前编译的时候应该是空缺了？）