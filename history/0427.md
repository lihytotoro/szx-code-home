# 0427 工作记录
今天准备重新开始之前一直暂停的工作
时间紧迫，需要加速了！

首先搞清楚我们的工作流程？
基本流程：train -> inference -> test

train：基于 full parameter/lora/qlora 进行全量/部分微调 情境下的训练，后续将对比三种训练模式之下的效果差异
inference: 基于训练所得到的 ckpt，在某些测试集上进行推理（例如，在 defects4j 的 483 条上进行推理，推理出修复的 fixed patch）
test: 对于有 test suite 的数据集来讲，进行正确性测试

今天的任务是：
1. 跑起来一些训练（之前看不懂的就不再看了，先重新训练上再说！）
2. 比较紧要的：修改成多轮对话的模式，这里可以利用 qlora 那边存在的 history 进行复用
3. 推理部分，其实也可以进行加速！看了之前的 vqa_eval 等部分，能不能将我的推理环节也改成多卡呢
4. 针对测试部分，写一下脚本？这里的脚本应该是指：进程级别的加速，相当于每个进程负责检测 10 个 beams 中的一个分支。由于检测一个分支也极其耗时，因此，这里应该可以改写成分别测试 483 个 bugs 中的一部分（比如设置 start_idx 和 end_idx！）

针对上面内容的补充：
1. 首先要跑起来的部分应该是之前的思路：即直接在 qwen 模型上进行一阶段微调之后（回答 CWE），在 codellama 模型上进行二阶段微调（接收 CWE 信息到注释中，回答 fixed patch）
2. 针对我和 cjb 交流得到的新思想，具体来讲，应该可以分为以下的部分：
    2.1 以 megadiff 数据集作为媒介，修改第一阶段（CWE类别推断）的流程
    2.2 进行数据增广，基于两种方式（大模型 or 规则，规则的话，之前看过论文），生成 good -> bad 的数据


# 实际进展
今天先去研究一下之前的 repairllama-cwe？ 也就是直接使用 juliet-CWE 数据微调 qwen（目前定的是 qwen，但是不知道强如 llama-3 效果如何呢？）
额外下载了新出的 llama-3-8b（both base and instruct），目前还在等待 pending 结果
之后有可能用这个模型和 qwen-7b 进行比较？

a. 训练第一阶段模型（最好多训几个！）
    a.0 full
    a.1 lora
    a.2 qlora (firefly)

昨天晚上的问题：没有跑起来训练，但是今天通过更新 torch 到 2.1.0(+cu118) 以及 peft、loguru、transformers、bitsandbytes 等库，跑起来了 qlora
进一步地，在训练 lora 的时候，出现了问题，与 fp16 有关，将 fp16 关闭，切换成 bf16 解决了！
这个方案沿用到 full 的版本中！

这里，我们使用 java-juliet 的 cwe-inference 数据进行一次尝试性的微调，看一下在 8 卡的情况下（实际上可能是数据并行），分别占用多少显存！
data: 约 55900
type    gpu     time        epoch   per_epoch_batch_size    gradient_accumulation_steps     float
----    ----    ----        ----    ----                    ----                            ----
full    14G？   4h          1       1                       16                              bf16
lora    26G     40min       1       1                       16                              bf16
qlora   19G     1h30min     1       1                       16                              fp16

上面的测试性实验结束之后，将 lhy conda 环境复制到 szx 环境，之后都用 szx 跑深圳的实验！

# 0428
今天由于 面壁 这边要花一整天训练 llama3 基座模型，因此抽出时间来优化一下推理和测试的代码？
目前主要可以优化的我认为有：
    1. 后续需要新版本的数据，也就是 buggy code + CWE type -> fixed code。由于目前，Firefly 的 lora、qlora、full 版本都已经在新的 conda 环境下跑通了，因此我们的任务主要是基于 Firefly 进行，生成数据的格式为 jsonl
    2. 由于新想法中，涉及用 java-juliet 微调 qwen 之后标注 megadiff 上的数据，因此，需要写一个基于微调后的模型回复，给每一条数据标注 CWE 类别的功能
    3. 针对 2 中的新思想，下一步：将 java-juliet 和 megadiff-cwe 合并，微调 codellama？这个之后再考虑
    4. 优先级在 3 之前，主要是实现命令行运行一轮次测试（甚至精确到一轮次里面的一部分？）

# 0430
今天尝试用 lora 和 qlora 各训练一版模型
